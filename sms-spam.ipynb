{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6113,"sourceType":"datasetVersion","datasetId":3901}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import StratifiedShuffleSplit #tine cont si de cls adica ia acelasi procent si de spam si de not spam\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-14T11:30:20.485275Z","iopub.execute_input":"2024-06-14T11:30:20.485548Z","iopub.status.idle":"2024-06-14T11:30:22.309541Z","shell.execute_reply.started":"2024-06-14T11:30:20.485522Z","shell.execute_reply":"2024-06-14T11:30:22.308636Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def get_data(filename):\n\n    df = pd.read_csv(filename, delimiter=',') #citim fisierul csv folosind delimitatorul ,\n    labels = df['type'].values #preluam labels .values sub forma unui np array\n    mesages = df['text'].values #preluam mesajele\n\n    pos_examples = np.sum(labels == 'ham') / labels.shape[0] # aduna toate exemplele pozitive 1 adica ham si le \n    #impartim la nr total de exemp ca sa obtinem procent, labels.shapep[0] tuplu cu prima pozitie nr de linii si a doua nr de coloane\n    neg_examples = 1 - pos_examples #procent exemple negative\n    print(\"procent exemple pozitive:\",pos_examples)\n    print(\"procent exemple negative:\",neg_examples)\n    \n\n    shuffle_stratified = StratifiedShuffleSplit(n_splits=1, test_size=0.2)\n    #daca in train avem 86% nospam si 13% spam ar fi indicat ca si la test aceleasi procente\n    #n_splits=1 ca doar un split vrem\n    #test_size=procentul pe care vrem sa l pastram in validare\n    #generaza 2 liste pe care le poti imparti in train si test\n    for train_index, test_index in shuffle_stratified.split(mesages, labels):\n        msg_train, msg_test = mesages[train_index], mesages[test_index]\n        labels_train, labels_test = labels[train_index], labels[test_index]\n    #splituim datasetul in train si test \n    \n    y_train = np.int32(labels_train == 'ham')\n    y_test = np.int32(labels_test == 'ham')\n    #traducem din 'ham' in 1 (valori numerice)\n    #practic facem un array cu 1 si 0, iar noi am pus\n    #ca atunci cand labels_train='ham' sa avem \"1\" adica true\n    #iar cand avem \"spam\" va da 0 adica false\n    print(\"valorile de 1 sunt ham si 0 sunt spam:\",y_train)\n\n    return msg_train, y_train, msg_test, y_test\n\n\nmsg_train, y_train, msg_test, y_test = get_data('/kaggle/input/spam-ham-sms-dataset/sms_spam.csv')\n\ncount_vectorizer = CountVectorizer(lowercase=True, analyzer='word', stop_words='english')\n#colectie de mesaje sms intr o matrice de numaratori de termeni\n#functie folosita la prelucrarea limbajului natural\n#lowercase true pt ca sa converteasca toate literele in lowercase\n#analyzer=word ca sa numere cuvintele, analiza se face la nivel de cuvant\n#stop_words=\"english\" elimina cuvintele comune in engleza (and, the, is, etc.)\ncount_vectorizer.fit(msg_train) #il antrenam\nX_train = count_vectorizer.transform(msg_train) \n#matricea de feature uri pt train\nX_test = count_vectorizer.transform(msg_test)\n#matricea de feature uri pt test\n\nmodel = MultinomialNB(alpha=0.01)\n#lucreaza bn cu feature uri de tip count, cum am numarat noi cuvintele\n#am modificat alfa pt acea problema unde o probabilitate conditionata e 0\n#pt ca nu au fost intalnite in train, corectie de tip Lidstone <1\nmodel.fit(X_train, y_train)\n\npredictions = model.predict(X_test)\n#realizam predictii pe datele de test\n\nprint(\"acuratetea:\",accuracy_score(y_test, predictions))\n#printam acuratetea modelului\nprint(classification_report(y_test, predictions))\n#calc automat recall precizie si f1score, cel mai imp fiind\n#recall ul maxim pt not spam, 0 spam si 1 not spam\n#precizie mare pt spam\n\n#În cazul în care setul nostru de testare este balansat (50% exemple pozitive - 50% exemple negative), acuratețea este o metodă bună de evaluare.\n#Problema apare atunci când testăm pe un set de date debalansat (ex: 90 negative 10 pozitive). În astfel de situații acuratețea ne poate duce în eroare.\n\n#precizia= tp/tp+fp \"cate chiar erau spam din cele clasificate ca spam?\"\n#Precizia ne ajută să ne dăm seama de corectitudinea prezicerilor noastre pentru o anumită clasă. \n#Practic, această metrică răspunde la întrebarea: “Care este procentul de rezultate prezise pe o anumită clasă care au fost prezise corect?”.\n\n#recall= tp/tp+fn \"cate chiar erau not spam din toate cele chiar sunt not spam?\"\n#se vrea maxim pt ca e de dorit sa fim siguri ca un mail nu e spam, mai bn afisam in mail cateva spam decat sa nu afisam un mail important pt ca a crezut ca e spam\n#Recall-ul ne indică câte rezultate corecte au fost prezise de model pentru o anumită clasă. \n#Întrebarea la care răspunde este: “Care este procentul de rezultate clasificate corect pentru o clasă din totalul de exemple din acea clasă?”.\n\n#F1score=Această metrică ține cont atât de precizie cât și de recall și reprezintă media armonică între cele 2.\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-14T11:30:22.311269Z","iopub.execute_input":"2024-06-14T11:30:22.311870Z","iopub.status.idle":"2024-06-14T11:30:22.747090Z","shell.execute_reply.started":"2024-06-14T11:30:22.311817Z","shell.execute_reply":"2024-06-14T11:30:22.745887Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"procent exemple pozitive: 0.8656233135456017\nprocent exemple negative: 0.13437668645439826\nvalorile de 1 sunt ham si 0 sunt spam: [1 1 1 ... 1 1 1]\nacuratetea: 0.9802158273381295\n              precision    recall  f1-score   support\n\n           0       0.92      0.93      0.93       149\n           1       0.99      0.99      0.99       963\n\n    accuracy                           0.98      1112\n   macro avg       0.96      0.96      0.96      1112\nweighted avg       0.98      0.98      0.98      1112\n\n","output_type":"stream"}]}]}